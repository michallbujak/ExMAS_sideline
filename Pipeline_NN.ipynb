{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b076c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import  DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aa4fcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "x_dim  = 2*20*10\n",
    "hidden_dim = 100\n",
    "latent_dim = 32\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 30\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e97ef7",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24baf101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 1, 2, 6, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 1, 3, 2, 5, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 2, 9, 0, 2, 0, 1, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 1, 1, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 3, 1, 2, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 2, 2, 4, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 1, 2, 3, 2, 1, 1, 2, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 4, 3, 1, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
       "        dtype=torch.int32),\n",
       " tensor(0.3149))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = torch.load('nyc_grid_shifted_train_dataset.pt')\n",
    "test_dataset = torch.load('nyc_grid_shifted_test_dataset.pt')\n",
    "\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52339ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3896"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60fb4feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.load('nyc_grid_shifted_train_dataset.pt')\n",
    "test_dataset = torch.load('nyc_grid_shifted_test_dataset.pt')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers = 4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7cd4ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2, 10, 20])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(train_loader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b70eb2",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb8ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.FC_input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.FC_input2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_mean  = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.FC_var   = nn.Linear (hidden_dim, latent_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.training = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_       = self.LeakyReLU(self.FC_input(x))\n",
    "        h_       = self.LeakyReLU(self.FC_input2(h_))\n",
    "        mean     = self.FC_mean(h_)\n",
    "        log_var  = self.FC_var(h_)                     \n",
    "        \n",
    "        return mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcbdf371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder2(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dim, input_channels):\n",
    "        super(Encoder2, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        modules = []\n",
    "        hidden_dims = [32, 64, 128, 256, 512,1000]\n",
    "        in_channels = input_channels\n",
    "\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=in_channels, out_channels=h_dim,\n",
    "                              kernel_size= 3, stride= 2, padding  = 1),\n",
    "                    nn.BatchNorm2d(h_dim),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "#         self.fc_mu = nn.Linear(hidden_dims[-1]*4, latent_dim)\n",
    "#         self.fc_var = nn.Linear(hidden_dims[-1]*4, latent_dim)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        \n",
    "        self.training = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        result = self.encoder(x)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "\n",
    "        return mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dcf73a",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a043b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.FC_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.FC_hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_output = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h     = self.LeakyReLU(self.FC_hidden(x))\n",
    "        h     = self.LeakyReLU(self.FC_hidden2(h))\n",
    "        \n",
    "        x_hat = torch.sigmoid(self.FC_output(h))\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee881bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder2(nn.Module):\n",
    "    def __init__(self, latent_dim, batch_size):\n",
    "        super(Decoder2, self).__init__()\n",
    "        \n",
    "        hidden_dims = [32, 64, 128, 256, 512]\n",
    "        hidden_dims.reverse()\n",
    "        \n",
    "#         self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1]*10*10)\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1])\n",
    "        \n",
    "        modules = []\n",
    "        \n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(hidden_dims[i],\n",
    "                                       hidden_dims[i + 1],\n",
    "                                       kernel_size=3,\n",
    "                                       stride = 2,\n",
    "                                       padding=1,\n",
    "                                       output_padding=1),\n",
    "                    nn.BatchNorm2d(hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Sequential(\n",
    "                            nn.ConvTranspose2d(hidden_dims[-1],\n",
    "                                               hidden_dims[-1],\n",
    "                                               kernel_size=3,\n",
    "                                               stride=2,\n",
    "                                               padding=1,\n",
    "                                               output_padding=1),\n",
    "                            nn.BatchNorm2d(hidden_dims[-1]),\n",
    "                            nn.LeakyReLU(),\n",
    "                            nn.Conv2d(hidden_dims[-1], out_channels= 2,\n",
    "                                      kernel_size= 3, padding= 1),\n",
    "                            nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print('Input for decoder: ', x.shape)\n",
    "        result = self.decoder_input(x)\n",
    "        print('Decoder_input:', result.shape)\n",
    "#         result = result.view(-1, 512, 2, 2)\n",
    "#         result = result.view(-1, 2, 10, 10)\n",
    "        print('Results shape:', result.shape)\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2fa5a2",
   "metadata": {},
   "source": [
    "### Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6e586b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "        \n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(DEVICE)        # sampling epsilon        \n",
    "        z = mean + var*epsilon                          # reparameterization trick\n",
    "        return z\n",
    "                  \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.Encoder(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n",
    "        x_hat = self.Decoder(z)\n",
    "        \n",
    "        return x_hat, mean, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fbe1ef",
   "metadata": {},
   "source": [
    "## Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ed124f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "# encoder2 = Encoder2(latent_dim=20, input_channels=2)\n",
    "decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = x_dim)\n",
    "# decoder2 = Decoder2(latent_dim=20, batch_size=batch_size)\n",
    "\n",
    "autoencoder = VAE(Encoder=encoder, Decoder=decoder).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f713d2",
   "metadata": {},
   "source": [
    "## Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd5b204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "BCE_loss = nn.BCELoss()\n",
    "\n",
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
    "    KLD      = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return reproduction_loss + KLD\n",
    "\n",
    "\n",
    "optimizer = Adam(autoencoder.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055baf2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "435bbc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training VAE...\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([64, 2, 10, 20])\n",
      "torch.Size([56, 2, 10, 20])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[64, 400]' is invalid for input of size 22400",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6524/10001302.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[64, 400]' is invalid for input of size 22400"
     ]
    }
   ],
   "source": [
    "print(\"Start training VAE...\")\n",
    "autoencoder.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    overall_loss = 0\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        print(x.shape)\n",
    "        x = x.view(batch_size, x_dim)\n",
    "        x = x.to(DEVICE)\n",
    "        x = x.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_hat, mean, log_var = autoencoder(x)\n",
    "        loss = loss_function(x, x_hat, mean, log_var)\n",
    "        \n",
    "        overall_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 5 == 0:\n",
    "        print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tAverage Loss: \", overall_loss / (batch_idx*batch_size))\n",
    "    \n",
    "print(\"Finish!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0d5c4b",
   "metadata": {},
   "source": [
    "# Grid NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd8e51f",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cae6edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 30\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f698d",
   "metadata": {},
   "source": [
    "#### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a0050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, padding=0):\n",
    "        super().__init__()\n",
    "        self.padding = padding\n",
    "        self.conv1 = nn.Conv2d(2, 8, 4, padding=self.padding, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 32, 3, padding=self.padding, stride=1)\n",
    "        self.conv1_drop = nn.Dropout2d()\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(448, 128)\n",
    "        self.fc2 = nn.Linear(128, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_drop(self.conv1(x)))\n",
    "        x = F.relu(self.conv2_drop(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c10535",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b51aa8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 2, 10, 20])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = torch.load('nyc_grid_shifted_train_dataset.pt')\n",
    "test_dataset = torch.load('nyc_grid_shifted_test_dataset.pt')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers = 4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True, num_workers = 4)\n",
    "\n",
    "x,y = next(iter(train_loader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0e52fe",
   "metadata": {},
   "source": [
    "#### Optimizer & criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72baf204",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(DEVICE)\n",
    "\n",
    "criterion = nn.MSELoss().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4113cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_losses_train = []\n",
    "    epoch_losses_test = []\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, kpis = data\n",
    "        \n",
    "        inputs = inputs.float().to(DEVICE)\n",
    "        kpis = kpis.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, kpis)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses_train.append(loss.item())\n",
    "\n",
    "        x, y = next(iter(test_loader))\n",
    "        x = x.float().to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        loss = criterion(y, net(x))\n",
    "        epoch_losses_test.append(loss.item())\n",
    "\n",
    "    train_loss.append(np.mean(epoch_losses_train))\n",
    "    test_loss.append(np.mean(epoch_losses_test))\n",
    "    if epoch % 10 == 9:\n",
    "        print(f' ####### Epoch: {epoch} #######')\n",
    "        print(f'Train loss: {train_loss[epoch]:.4f}')\n",
    "        print(f'Test loss: {test_loss[epoch]:.4f}')\n",
    "        print('\\n')\n",
    "plt.plot(train_loss, label='Train loss')\n",
    "plt.plot(test_loss, label='Test loss')\n",
    "plt.legend(title='Loss with respect to epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c19e07c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
