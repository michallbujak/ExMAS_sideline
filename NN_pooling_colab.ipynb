{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ecb8fc6",
   "metadata": {
    "id": "koP4F4j0GF0D"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import  DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6948497",
   "metadata": {
    "id": "3oLc0hhIEhKl"
   },
   "outputs": [],
   "source": [
    "with open('demand_nyc_full_shifted_t.obj', 'rb') as file:\n",
    "    demand = pickle.load(file)\n",
    "\n",
    "with open('kpis_nyc.obj', 'rb') as file:\n",
    "    exmas_res_extracted = pickle.load(file)\n",
    "\n",
    "def nyc_grid_apply(demand, x_name_org='x_org', x_name_dest='x_dest', y_name_org='y_org', y_name_dest='y_dest',\n",
    "                   x_num=21, y_num=11):\n",
    "    x_min = min([min(np.concatenate([d[x_name_org].values, d[x_name_dest].values])) for d in demand])\n",
    "    x_max = max([max(np.concatenate([d[x_name_org].values, d[x_name_dest].values])) for d in demand])\n",
    "    y_min = min([min(np.concatenate([d[y_name_org].values, d[y_name_dest].values])) for d in demand])\n",
    "    y_max = max([max(np.concatenate([d[y_name_org].values, d[y_name_dest].values])) for d in demand])\n",
    "    x_grid = np.linspace(x_min, x_max, num=x_num)\n",
    "    y_grid = np.linspace(y_min, y_max, num=y_num)\n",
    "    o = [np.histogram2d(d[y_name_org], d[x_name_org], bins=[y_grid, x_grid])[0].astype(int) for d in demand]\n",
    "    d = [np.histogram2d(d[y_name_dest], d[x_name_dest], bins=[y_grid, x_grid])[0].astype(int) for d in demand]\n",
    "    o = [torch.from_numpy(x) for x in o]\n",
    "    d = [torch.from_numpy(x) for x in d]\n",
    "    return [torch.stack([x, y], dim=0) for x, y in zip(o, d)]\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, demand, labels):\n",
    "        self.demand = demand\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.demand[index].float(), self.labels[index].float()\n",
    "\n",
    "demand_list_tensors = nyc_grid_apply(demand, x_num=61, y_num=31)\n",
    "results_list_tensors = [torch.tensor(a) for a in exmas_res_extracted]\n",
    "dataset = Dataset(demand_list_tensors, results_list_tensors)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9a219a5",
   "metadata": {
    "id": "hr14vUnKB3uA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('demand_nyc_full_shifted_t.obj', 'rb') as file:\n",
    "    demand = pickle.load(file)\n",
    "\n",
    "with open('kpis_nyc.obj', 'rb') as file:\n",
    "    exmas_res_extracted = pickle.load(file)\n",
    "\n",
    "demand_amended = []\n",
    "for d in demand:\n",
    "  d['Actual_ride'] = 1\n",
    "  df_to_append = pd.DataFrame(np.zeros((200 - len(d), 6)), columns=d.columns)\n",
    "  d = pd.concat([d, df_to_append], ignore_index=True)\n",
    "  demand_amended.append(torch.tensor(np.matrix(d)))\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, demand, labels):\n",
    "        self.demand = demand\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.demand[index].float(), self.labels[index].float()\n",
    "\n",
    "\n",
    "\n",
    "results_list_tensors = [torch.tensor(a) for a in exmas_res_extracted]\n",
    "dataset = Dataset(demand_amended, results_list_tensors)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5685af12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OgjBAZFAGdvL",
    "outputId": "21684bc1-c929-42c2-a008-e04913bc7afd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "lr = 1e-4\n",
    "epochs = 50\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae10be7",
   "metadata": {
    "id": "LiM1VV4CGngl"
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.load('nyc_grid_full_shifted_train_dataset.pt')\n",
    "test_dataset = torch.load('nyc_grid_full_shifted_test_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e02853",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yv2ADJimMbLq",
    "outputId": "f412ee3f-a5e0-42f8-a9f8-c1a6550ce9ea"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers = 4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da6d7e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PtqO7VQpMddR",
    "outputId": "296e03b4-47e4-44d9-e98c-85eca6538605"
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(train_loader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b79d4",
   "metadata": {
    "id": "CltPQtZtMfix"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, conv_size, h1, h2, padding=0):\n",
    "        super().__init__()\n",
    "        self.padding = padding\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, padding=self.padding, stride=1)\n",
    "        self.conv2 = nn.Conv2d(8, 32, 3, padding=self.padding, stride=1)\n",
    "        self.conv1_drop = nn.Dropout2d()\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(conv_size, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_drop(self.conv1(x)))\n",
    "        x = F.relu(self.conv2_drop(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfbd1af",
   "metadata": {
    "id": "Jgrhwqj3Fua1"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_features, nh1, nh2):\n",
    "        super(Net, self).__init__()\n",
    "        self.h1 = torch.nn.Linear(n_features, nh1)\n",
    "        self.h2 = torch.nn.Linear(nh1, nh2)\n",
    "        self.predict = torch.nn.Linear(200*nh2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.h1(x))\n",
    "        x = F.leaky_relu(self.h2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.predict(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0599d1",
   "metadata": {
    "id": "RU0PuV8jNKx7"
   },
   "outputs": [],
   "source": [
    "net = Net(12544, 128, 64).to(DEVICE)\n",
    "\n",
    "criterion = nn.MSELoss().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c03489",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VTOUAEcwNQa0",
    "outputId": "0019517a-7e97-4238-c7a6-cc5ba8d47d11"
   },
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_losses_train = []\n",
    "    epoch_losses_test = []\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, kpis = data\n",
    "        \n",
    "        inputs = inputs.float().to(DEVICE)\n",
    "        kpis = kpis.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        inputs = torch.unsqueeze(inputs, 1)\n",
    "        # print(inputs.shape)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, kpis)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses_train.append(loss.item())\n",
    "\n",
    "        x, y = next(iter(test_loader))\n",
    "        x = x.float().to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "\n",
    "        loss = criterion(y, net(x))\n",
    "        epoch_losses_test.append(loss.item())\n",
    "\n",
    "    train_loss.append(np.mean(epoch_losses_train))\n",
    "    test_loss.append(np.mean(epoch_losses_test))\n",
    "    if epoch % 10 == 9:\n",
    "        print(f' ####### Epoch: {epoch} #######')\n",
    "        print(f'Train loss: {train_loss[epoch]:.4f}')\n",
    "        print(f'Test loss: {test_loss[epoch]:.4f}')\n",
    "        print('\\n')\n",
    "plt.plot(train_loss, label='Train loss')\n",
    "plt.plot(test_loss, label='Test loss')\n",
    "plt.legend(title='Loss with respect to epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a3797f",
   "metadata": {
    "id": "N7tMO_alMWKo"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_loader2 = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True, num_workers = 4)\n",
    "\n",
    "x, y = next(iter(test_loader2))\n",
    "x = x.float().to(DEVICE)\n",
    "# l = net(x).cpu().detach().numpy().tolist()\n",
    "# predicted = [k[0] for k in l]\n",
    "predicted = [t[0].detach().numpy().tolist() for t in net(x).cpu()]\n",
    "# actual = [t[0].numpy().tolist() for t in y]\n",
    "\n",
    "plt.scatter(y, predicted)\n",
    "plt.xlim(-0.5,0.1)\n",
    "plt.ylim(-0.5,0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a6600",
   "metadata": {
    "id": "qdJWur_vR-8j"
   },
   "outputs": [],
   "source": [
    "predicted[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589d43f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
